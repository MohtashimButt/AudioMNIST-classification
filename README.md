# AudioMNIST-classification

- This task delves into the realm of audio signal processing and machine learning. I created a Deep Neural Networks using PyTorch to perform this classification task.
- The dataset used is `AudioMNIST` dataset: tens of thousands of audio samples of people with different accents, coming from different regions of the world, speaking different digits. You can download the dataset using [this link](https://drive.google.com/file/d/1EDbjnXFlmdnru1N36KpQR054dSpsixW8/view?usp=sharing).
- I used MFCCs to extract features from audio and PyTorch to classify audio.
- The classifier has `Train Acc: 0.9466` and `Val acc: 0.9323` with the following plots:

![losses](url daal)

### How to use this work?
- Clone the repository by using the following command:
```
git clone https://github.com/MohtashimButt/AudioMNIST-classification
```
- Use the file `NB.ipynb`. (the notebook is self-explanatory with the comments added to each step being taken)
